{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "temporal-affiliation",
   "metadata": {},
   "source": [
    "# 2110443 - Computer Vision (2020/2)\n",
    "## Lab 5 - Texture\n",
    "In this lab, we will learn to use texture to segment 'things' from images. This notebook includes both coding and written questions. Please hand in this notebook file with all outputs and your answer. <br>\n",
    "<b>Please note that collaboration is encouraged in this course.</b> You must turn in <b>your own write ups</b> of all problems. If you collaborate with others, you must put the names and ids of the students you worked with in below block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-nomination",
   "metadata": {},
   "source": [
    "Collaboration List:\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-ranking",
   "metadata": {},
   "source": [
    "<b>Remark : You need to install addition package name 'scikit-image' by using the following command line</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install scikit-image -c conda-forge -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io, color\n",
    "from skimage.feature import local_binary_pattern, greycomatrix, greycoprops\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-league",
   "metadata": {},
   "source": [
    "## Gray Level Co-Occurrence Matrix (GLCM)\n",
    "A gray level co-occurrence Matrix is a matrix that is defined over an image to be the distribution of co-occurring pixel values at a given offset. It is used as an approach to texture analysis with various computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "patternImage = np.array([\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 2, 2, 2],\n",
    "    [0, 2, 3, 3]], dtype=np.uint8)\n",
    "\n",
    "plt.imshow(patternImage, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-venezuela",
   "metadata": {},
   "source": [
    "We will use <a href=\"https://scikit-image.org/docs/dev/api/skimage.feature.html?highlight=lbp#skimage.feature.greycomatrix\">greycomatrix</a> function from scikit-image to extract GLCM from the sample pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ocmatrix = greycomatrix(patternImage, distances=[1], angles=[0, np.pi/4, np.pi/2], levels=4)\n",
    "\n",
    "print('angle 0')\n",
    "print(co_ocmatrix[:,:,0,0])\n",
    "\n",
    "print('angle 45')\n",
    "print(co_ocmatrix[:,:,0,1])\n",
    "\n",
    "print('angle 90')\n",
    "print(co_ocmatrix[:,:,0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-space",
   "metadata": {},
   "source": [
    "### GLCM texture properties\n",
    "Fron the  GLCM we can compute the following texture properties by using <a href=''>greycoprops</a> from scikit-image\n",
    "- contrast $\\sum_{i,j=0}^{levels-1} P_{i,j}(i-j)^2$\n",
    "- dissimilarity $\\sum_{i,j=0}^{levels-1}P_{i,j}|i-j|$\n",
    "- homogeneity $\\sum_{i,j=0}^{levels-1}\\frac{P_{i,j}}{1+(i-j)^2}$\n",
    "- correlation $\\sum_{i,j=0}^{levels-1} P_{i,j}\\left[\\frac{(i-\\mu_i)(j-\\mu_j)}{\\sqrt{(\\sigma_i^2)(\\sigma_j^2)}}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = greycoprops(co_ocmatrix, prop='contrast')\n",
    "dissimilarity = greycoprops(co_ocmatrix, prop='dissimilarity')\n",
    "\n",
    "print(contrast, dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "patternImage2 = np.zeros((4,4), dtype=np.uint8) ## all black image!\n",
    "co_ocmatrix2 = greycomatrix(patternImage2, distances=[1], angles=[0, np.pi/4, np.pi/2])\n",
    "\n",
    "contrast2 = greycoprops(co_ocmatrix2, prop='contrast')\n",
    "dissimilarity2 = greycoprops(co_ocmatrix2, prop='dissimilarity')\n",
    "homogeneity2 = greycoprops(co_ocmatrix2, prop='homogeneity')\n",
    "\n",
    "print(contrast2, dissimilarity2, homogeneity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-administrator",
   "metadata": {},
   "source": [
    "### Co-Occurrence matrix patch matching on bridge defect problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridgeDefectImage = cv2.imread('assets/Lab5-crack.jpg')\n",
    "dispImage = cv2.cvtColor(bridgeDefectImage.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Sample crack\n",
    "cv2.rectangle(dispImage, (170,200), (220,250), (0,255,255), 5)\n",
    "\n",
    "# Normal1\n",
    "cv2.rectangle(dispImage, (400,400), (450,450), (255,255,0), 5)\n",
    "\n",
    "# Crack2\n",
    "cv2.rectangle(dispImage, (540,300), (590,350), (0,255,0), 5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(dispImage, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridgeDefectImageGray = cv2.cvtColor(bridgeDefectImage, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "crackPatch1 = bridgeDefectImageGray[200:250,170:220]\n",
    "\n",
    "normalPatch1= bridgeDefectImageGray[400:450,400:450]\n",
    "\n",
    "crackPatch2 = bridgeDefectImageGray[300:350,540:590]\n",
    "\n",
    "_, axarr = plt.subplots(1,3)\n",
    "axarr[0].imshow(crackPatch1, cmap='gray')\n",
    "axarr[1].imshow(normalPatch1, cmap='gray')\n",
    "axarr[2].imshow(crackPatch2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_ocmatrix_crackpatch1 = greycomatrix(crackPatch1, distances=[1], angles=[0, np.pi/4, np.pi/2], symmetric=True, normed=True)\n",
    "\n",
    "co_ocmatrix_normalpatch1 = greycomatrix(normalPatch1, distances=[1], angles=[0, np.pi/4, np.pi/2], symmetric=True, normed=True)\n",
    "\n",
    "co_ocmatrix_crackpatch2 = greycomatrix(crackPatch2, distances=[1], angles=[0, np.pi/4, np.pi/2], symmetric=True, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_normal_normal = np.linalg.norm(co_ocmatrix_crackpatch1-co_ocmatrix_crackpatch2)\n",
    "print('distance crack-crack', dist_normal_normal)\n",
    "\n",
    "dist_normal_crack = np.linalg.norm(co_ocmatrix_crackpatch1-co_ocmatrix_normalpatch1)\n",
    "print('distance normal-crack', dist_normal_crack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-afghanistan",
   "metadata": {},
   "source": [
    "## Local Binary Pattern (LBP)\n",
    "Local Binary Pattern (LBP) is a efficient texture operator which labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number.  It can be seen as a unifying approach to the traditionally divergent statistical and structural models of texture analysis. The most important property of the LBP operator in real-world applications is its robustness to monotonic gray-scale changes caused, for example, by illumination variations. Another important property is its computational simplicity, which makes it possible to analyze images in challenging real-time settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "patternImage = np.array([\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 2, 2, 2],\n",
    "    [0, 2, 3, 3]], dtype=np.uint8)\n",
    "\n",
    "plt.imshow(patternImage, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbpfeature = local_binary_pattern(patternImage, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lbpfeature, cmap='gray')\n",
    "print(lbpfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridgeDefectImage = cv2.imread('assets/Lab5-crack.jpg')\n",
    "dispImage = cv2.cvtColor(bridgeDefectImage.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Sample crack\n",
    "cv2.rectangle(dispImage, (170,200), (220,250), (0,255,255), 5)\n",
    "\n",
    "# Normal1\n",
    "cv2.rectangle(dispImage, (400,400), (450,450), (255,255,0), 5)\n",
    "\n",
    "# Crack2\n",
    "cv2.rectangle(dispImage, (540,300), (590,350), (0,255,0), 5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(dispImage, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-honor",
   "metadata": {},
   "source": [
    "Calculate LBP pattern for each patch by using scikit-image <a href=\"https://scikit-image.org/docs/dev/api/skimage.feature.html?highlight=lbp#skimage.feature.local_binary_pattern\">local_binary_pattern</a> <br>\n",
    "<img src=\"assets/Lab5-LBP.jpg\"/><br> Three neighborhood examples with varying p and r used to construct Local Binary Patterns. (Image from <a href=\"https://www.pyimagesearch.com/2015/12/07/local-binary-patterns-with-python-opencv/\">pyimagesearch</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_crackpatch1 =  local_binary_pattern(crackPatch1, P=16, R=8, method='uniform') \n",
    "lbp_normalpatch1 =  local_binary_pattern(normalPatch1, P=16, R=8, method='uniform')\n",
    "lbp_crackpatch2 =  local_binary_pattern(crackPatch2, P=16, R=8, method='uniform') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-musician",
   "metadata": {},
   "source": [
    "### LBP histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "nBin = 16\n",
    "\n",
    "_, axarr = plt.subplots(1,3)\n",
    "\n",
    "hist_crackpatch1, _ = np.histogram(lbp_crackpatch1, density=True, bins=nBin, range=(0, nBin))\n",
    "axarr[0].plot(hist_crackpatch1)\n",
    "\n",
    "hist_normalpatch1, _ = np.histogram(lbp_normalpatch1, density=True, bins=nBin, range=(0, nBin))\n",
    "axarr[1].plot(hist_normalpatch1)\n",
    "    \n",
    "hist_crackpatch2, _ = np.histogram(lbp_crackpatch2, density=True, bins=nBin, range=(0, nBin))\n",
    "axarr[2].plot(hist_crackpatch2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-rochester",
   "metadata": {},
   "source": [
    "### LBP Histogram matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-refrigerator",
   "metadata": {},
   "source": [
    "#### Simple euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eucliden distance between crack-crack',np.linalg.norm(hist_crackpatch1 - hist_crackpatch2))\n",
    "print('Eucliden distance between crack-normal',np.linalg.norm(hist_crackpatch1 - hist_normalpatch1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-insertion",
   "metadata": {},
   "source": [
    "#### KL divergence is a way of measuring the matching between two distributions \n",
    "(More detail can  be read from <a href=\"https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8\">here</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kldivergence(p, q):\n",
    "    filt = np.logical_and(p != 0, q != 0)\n",
    "    return np.sum(p[filt] * np.log2(p[filt] / q[filt]))\n",
    "\n",
    "print('KL-Divergence between crack-crack', kldivergence(hist_crackpatch1 , hist_crackpatch2))\n",
    "print('KL-Divergence between crack-normal', kldivergence(hist_crackpatch1 , hist_normalpatch1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-validation",
   "metadata": {},
   "source": [
    "## Assignment 1 - Texture Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-rescue",
   "metadata": {},
   "source": [
    "From the above section, we can magically matching each texture with sample patches. Your today task is to implement a program to segment this leopard from the background by using chosen texture feature and sliding window method. You can search and use any knowledge from internet but do not forget to proper credit your sources. <br>\n",
    "<img src=\"assets/Lab5-leopard.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "leopardImage = cv2.imread('assets/Lab5-leopard.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "leopardImage = cv2.resize(leopardImage, None,fx=0.5,fy=0.5) #resize to reduce computation time\n",
    "\n",
    "# Just sample patches, you can change to any position you want\n",
    "leopardPatch1 = leopardImage[100:150,400:450]\n",
    "leopardPatch2 = leopardImage[100:150,150:200]\n",
    "leopardPatch3 = leopardImage[200:250,300:350]\n",
    "\n",
    "nonleopardPatch1 = leopardImage[0:50,400:450]\n",
    "nonleopardPatch2 = leopardImage[250:300,0:50]\n",
    "nonleopardPatch3 = leopardImage[250:300,100:150]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(leopardImage, cmap='gray')\n",
    "\n",
    "plt.figure()\n",
    "_, axarr = plt.subplots(1,3)\n",
    "axarr[0].imshow(leopardPatch1, cmap='gray')\n",
    "axarr[1].imshow(leopardPatch2, cmap='gray')\n",
    "axarr[2].imshow(leopardPatch3, cmap='gray')\n",
    "\n",
    "plt.figure()\n",
    "_, axarr = plt.subplots(1,3)\n",
    "axarr[0].imshow(nonleopardPatch1, cmap='gray')\n",
    "axarr[1].imshow(nonleopardPatch2, cmap='gray')\n",
    "axarr[2].imshow(nonleopardPatch3, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-pipeline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
