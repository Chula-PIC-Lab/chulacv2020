{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 8 - Convolutional Neural Network [Homework]",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eijcmIWOr39B"
      },
      "source": [
        "# **2110443 - Computer Vision (2020/2)**\n",
        "#**Lab 8 - Convolutional Neural Network [Homework]** <br>\n",
        "In this lab, we will learn how to use Convolutional Neural Network to perform image classification in the provided real world dataset using PyTorch. This notebook includes both coding and written questions. Please hand in this notebook file with all outputs and your answer.\n",
        "\n",
        "**Collaboration is encouraged in this course.** You must turn in your own write ups of all problems. If you collaborate with others, you must put the names and ids of the students you worked with in below block.\n",
        "\n",
        "Collaboration List:\n",
        "- ...\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q51z8PMXfLyh"
      },
      "source": [
        "# Assignment 1 : Face Mask Image Classification\n",
        "![alt text](https://raw.githubusercontent.com/AIZOOTech/FaceMaskDetection/master/img/demo.png)\n",
        "\n",
        "Detect faces and determine whether masks are worn or not.\n",
        "\n",
        "Dataset from : [AIZOOTech/FaceMaskDetection](https://github.com/AIZOOTech/FaceMaskDetection)\n",
        "\n",
        "In this assignment you have to replace YOUR_STUDENT_ID_WITH21 variable with your student id (in integer). There will be 3 sets of data: train, test and validation in the following folders:\n",
        "\n",
        "*   facemask/train (with labels)\n",
        "*   facemask/test (with labels)\n",
        "*   facemask/val (unknown label)\n",
        "\n",
        "By using the knowledge from the lab and lecture, you have to design your own CNN face mask image classification model and tested on unknown label dataset!\n",
        "\n",
        "\n",
        "\n",
        "Scoreboard URL : https://www.piclab.ai/classes/cv2020/lab8/scoreboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynMThy4kbk4G"
      },
      "source": [
        "import random\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torchvision import models as models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "##### Don't forget to put your ID here (in integer) ####\n",
        "YOUR_STUDENT_ID_WITH21 = 5971451121 \n",
        "#######################################################\n",
        "\n",
        "def isStudentIDValid(studentID):\n",
        "  strID = str(studentID)\n",
        "  isEndWith21 = strID.endswith('21')\n",
        "  isLengthOK = len(strID) == 10\n",
        "  if isEndWith21 and isLengthOK:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "print('Student ID status:',isStudentIDValid(YOUR_STUDENT_ID_WITH21))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9zPv07crmK9"
      },
      "source": [
        "## Your model description goes here: ###\n",
        "WRITE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDDMTmU8f7AJ"
      },
      "source": [
        "##GPU Status Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkMFsz71gFUy"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItsX7viBgHVS"
      },
      "source": [
        "## Download and inspect face mask dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKXJyE8cKV0"
      },
      "source": [
        "!wget  -O facemask.zip https://www.piclab.ai/classes/cv2020/facemask.zip\n",
        "!unzip -qo facemask.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOUMO-oRgPIe"
      },
      "source": [
        "### Helper function to display image from dataset ###\n",
        "def getImageFromDataset(dataset, idx):\n",
        "  sampleImage, sampleLabel = dataset.__getitem__(idx)\n",
        "  ### Revert transformation ###\n",
        "  sampleImage = ((sampleImage.permute(1,2,0).numpy() * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406]))*255\n",
        "  sampleImage = sampleImage.astype(np.uint8)\n",
        "  sampleClassName = dataset.classes[sampleLabel]\n",
        "  return sampleImage, sampleClassName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALFZbGlOb0QL"
      },
      "source": [
        "#### FILL Any Augmenetation HERE ####\n",
        "transformTrain = transforms.Compose([\n",
        "        transforms.Resize(size=(224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "transformTest =  transforms.Compose([\n",
        "        transforms.Resize(size=(224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "### Load Dataset ###\n",
        "faceMaskTrainDataset = \n",
        "faceMaskTestDataset = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtY4pFYLgXMb"
      },
      "source": [
        "## Dataset Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygdZ_mQ7gV95"
      },
      "source": [
        "normalImage, normalClassName = getImageFromDataset(faceMaskTrainDataset, 0)\n",
        "maskImage, maskClassName = getImageFromDataset(faceMaskTrainDataset, 4000)\n",
        "\n",
        "_, figure = plt.subplots(1,2)\n",
        "\n",
        "figure[0].imshow(normalImage,cmap='gray')\n",
        "figure[0].title.set_text(normalClassName)\n",
        "\n",
        "figure[1].imshow(maskImage,cmap='gray')\n",
        "figure[1].title.set_text(maskClassName)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SbeT8fTgprL"
      },
      "source": [
        "## Define CNN network for face mask classification\n",
        "Hint\n",
        "1. You can freely uses any structure/pretrained model to do this homework but don't forgot to cited them in this notebook.\n",
        "\n",
        "   A very big collection of pretrained model can be found here : https://github.com/rwightman/pytorch-image-models\n",
        "\n",
        "2. Don't forget to change mean and std in the pre-processing to match with your pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9UgoSjIb57S"
      },
      "source": [
        "#### Design you network here ####\n",
        "class faceMaskNet(nn.Module):\n",
        "  def __init__(self,)\n",
        "    super(faceMaskNet, self).__init__()\n",
        "    ### Layers goes here ###\n",
        "  def forward(self, input):\n",
        "    ### Conntections goes here ###\n",
        "    return ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2uj_-gTgxIw"
      },
      "source": [
        "## Construct the model, optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3ysKN-AcNnO"
      },
      "source": [
        "#### FILL HERE ####\n",
        "faceMaskNet.cuda()\n",
        "\n",
        "criterion = \n",
        "optimizer = \n",
        "scheduler =\n",
        "\n",
        "faceMaskTrainDatasetLoader = \n",
        "faceMaskTestDatasetLoader = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-2hcRGg54i"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ViDa1Cda7d"
      },
      "source": [
        "### Train and test helper function ###\n",
        "def testModel(testDatasetLoader, net):\n",
        "  net.eval()\n",
        "  correctImages = 0\n",
        "  totalImages = 0\n",
        "  allLabels = []\n",
        "  allPredicted = []\n",
        "  testingProgressbar = tqdm(enumerate(testDatasetLoader), total=len(testDatasetLoader), ncols='100%')\n",
        "  with torch.no_grad():\n",
        "    for batchIdx, batchData in testingProgressbar:\n",
        "      images, labels = batchData\n",
        "      \n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "      correctImages += (predicted == labels).sum().item()\n",
        "      totalImages += labels.size(0)\n",
        "\n",
        "      accumulateAccuracy = round((correctImages/totalImages)*100,4)\n",
        "      testingProgressbar.set_description(\"Testing accuracy: {}\".format(accumulateAccuracy ) )\n",
        "    \n",
        "      allLabels.append(labels)\n",
        "      allPredicted.append(predicted)\n",
        "  allLabels = torch.cat(allLabels).cpu().numpy()\n",
        "  allPredicted = torch.cat(allPredicted).cpu().numpy()\n",
        "  return correctImages, totalImages, allLabels, allPredicted\n",
        "\n",
        "def trainAndTestModel(trainDatasetLoader, testDatasetLoader, net, optimizer,scheduler, criterion, trainEpoch):\n",
        "  \n",
        "  bestAccuracy = 0\n",
        "  correctImages = 0\n",
        "  totalImages = 0\n",
        "  for currentEpoch in tqdm(range(trainEpoch), desc='Overall Training Progress:', ncols='100%'):\n",
        "    trainingLoss = 0.0\n",
        "    net.train()\n",
        "    print('Epoch',str(currentEpoch+1),'/',str(trainEpoch))\n",
        "    trainingProgressbar = tqdm(enumerate(trainDatasetLoader), total=len(trainDatasetLoader), ncols='100%')\n",
        "    for batchIdx, batchData in trainingProgressbar:\n",
        "      images, labels = batchData\n",
        "      images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "    \n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correctImages += (predicted == labels).sum().item()\n",
        "      totalImages += labels.size(0)\n",
        "    \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "\n",
        "      trainingLoss += loss.item()\n",
        "      accumulateAccuracy = round((correctImages/totalImages)*100,4)\n",
        "      trainingProgressbar.set_description(\"Training accuracy: {} loss: {}\".format(accumulateAccuracy, round(loss.item(),4) ) )\n",
        "    scheduler.step(trainingLoss)\n",
        "    correctImages, totalImages, allLabels, allPredicted = testModel(testDatasetLoader, net)\n",
        "    testAccuracy = round((correctImages/totalImages)*100,2)\n",
        "\n",
        "    print('='*10)\n",
        "    \n",
        "    if testAccuracy > bestAccuracy:\n",
        "      bestAccuracy = testAccuracy\n",
        "      bestPredicted = allPredicted\n",
        "      bestNet = net\n",
        "\n",
        "  return bestAccuracy, bestPredicted, allLabels, bestNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ogG_MRacSjm"
      },
      "source": [
        "bestAccuracy, bestPredicted, allLabels, bestNet = trainAndTestModel(??)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AitnH508hAUk"
      },
      "source": [
        "## Find the confusion matrix and calculate TP, TN, FP, and FN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvMAuTR2dq71"
      },
      "source": [
        "### Confusion matrix plot helper function from https://www.kaggle.com/grfiv4/plot-a-confusion-matrix ###\n",
        "def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "            \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRoFOS_edsnc"
      },
      "source": [
        "confusionMatrix = confusion_matrix(allLabels, bestPredicted)\n",
        "plot_confusion_matrix(cm           = confusionMatrix, \n",
        "                      normalize    = False,\n",
        "                      target_names = faceMaskTrainDataset.classes,\n",
        "                      title        = \"Face Mask Classification Confusion Matrix\")\n",
        "tn, fp, fn, tp = confusionMatrix.ravel()\n",
        "print('TP:{} TN:{} FP:{} FN:{}'.format(tn, fp, fn, tp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcJEcscDhD6D"
      },
      "source": [
        "## Classify on validation set and send result to server!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S59bPBW3duMw"
      },
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "import requests\n",
        "\n",
        "class ImageFolderWithPaths(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.imageFileNames = sorted(glob.glob(root_dir+'/*.jpg'))\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        imageData = Image.open(self.imageFileNames[idx])\n",
        "        imageFileName = os.path.basename(self.imageFileNames[idx])\n",
        "        if self.transform is not None:\n",
        "            imageData = self.transform(imageData)\n",
        "        return imageFileName, imageData.unsqueeze(0)\n",
        "    def __len__(self):\n",
        "        return len(self.imageFileNames)\n",
        "\n",
        "\n",
        "\n",
        "def generatePredictedResults(valDataset, net):\n",
        "    net.eval()\n",
        "    predictedResults = {}\n",
        "    with torch.no_grad():\n",
        "        for imageFileName, imageData in tqdm(valDataset, ncols='100%'):\n",
        "            imageData = imageData.cuda()\n",
        "            outputs = net(imageData)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            #print(imageFileName, predicted.item())\n",
        "            predictedResults[imageFileName] =  predicted.item()\n",
        "    return predictedResults\n",
        "\n",
        "def sendResult(predictedResults,studentID=5871451121):\n",
        "    sendDict = { 'studentID':studentID, 'results':  predictedResults }\n",
        "    response = requests.post('https://www.piclab.ai/classes/cv2020/lab8/scoreboard/submit',headers={'Content-Type': 'application/json' }, json=sendDict)\n",
        "    return response.text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OJAvoBVpkEE"
      },
      "source": [
        "Example Result JSON <br>\n",
        "resultDict = { \n",
        "  'studentID': 555555555521,\n",
        "  'results':{\n",
        "    '1.jpg':0,\n",
        "    '2.jpg':1,\n",
        "    ...\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUajK45GeA3n"
      },
      "source": [
        "faceMaskValDataset = ImageFolderWithPaths('facemask/val/', transform=transformTest)\n",
        "predictedResults = generatePredictedResults(faceMaskValDataset, bestNet)\n",
        "print(sendResult(predictedResults, studentID=YOUR_STUDENT_ID_WITH21))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}